import torch.backends.cudnn as cudnn
from torch.autograd import Variable
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter

import argparse
from tqdm import trange
import os
from importlib.machinery import SourceFileLoader
import numpy as np
import matplotlib.pyplot as plt

from utils.utils import *

def custom_psf_loss(output_psf, target_radius, device):
    """
    Custom loss function to encourage light intensity to be low at the center
    and higher at the periphery.

    Args:
    - output_psf (torch.Tensor): The PSF tensor generated by the model.
    - target_radius (int): Radius defining the central region to minimize intensity.
    - device (str): Device to perform computations ('cpu' or 'cuda').

    Returns:
    - torch.Tensor: Calculated loss.
    """
    dim = output_psf.shape[-1]  # Assuming square PSF for simplicity
    center = dim // 2
    Y, X = torch.meshgrid(torch.arange(dim), torch.arange(dim), indexing='ij')
    Y, X = Y.to(device), X.to(device)

    # Calculate the distance from the center
    distances = torch.sqrt((Y - center) ** 2 + (X - center) ** 2)
    
    # Create a mask for the center area
    center_mask = (distances < target_radius).float()

    # Calculate loss: high penalty for center, low penalty for periphery
    center_loss = (output_psf * center_mask).sum() / center_mask.sum()
    periphery_loss = (output_psf * (1 - center_mask)).sum() / (1 - center_mask).sum()

    # Combine losses: Minimize center loss and maximize periphery loss
    loss = 4*center_loss - periphery_loss
    return loss

def train_step(DOE_phase, optics_optimizer, total_steps, psf_far, far_depth, near_depth, args):
    param = args.param
    DOE_train = DOE((1,1,param.R, param.R), param.DOE_pitch, param.material, wvl=param.DOE_wvl, device='cpu')
    DOE_train.set_phase_change(DOE_phase)

    doe_psf_far = []
    doe_psf_near = []

    for depth in far_depth:
        doe_psf_far.append(compute_psf_Fraunhofer(wvl=param.DOE_wvl, depth=torch.tensor(depth), doe=DOE_train, args=args))
    
    for depth in near_depth:
        doe_psf_near.append(compute_psf_Fraunhofer(wvl=param.DOE_wvl, depth=torch.tensor(depth), doe=DOE_train, args=args))

    # Far PSF loss
    far_loss = 0
    for i in range(len(far_depth)):
        far_loss += args.l1_criterion(doe_psf_far[i], psf_far[i])
    far_loss /= len(far_depth)

    # Near PSF loss
    target_radius = 200
    near_loss = 0
    for i in range(len(near_depth)):
        near_loss += custom_psf_loss(doe_psf_near[i], target_radius, args.device)
    near_loss /= len(near_depth)

    # total loss
    total_loss = 100000*far_loss + 50000*near_loss

    # log loss
    print('\n Far Loss: %f, Near Loss: %f' % (100000*far_loss, 50000*near_loss))

    optics_optimizer.zero_grad()  
    total_loss.backward()
    optics_optimizer.step()

    return total_loss.detach()

def train(args):

    writer = SummaryWriter(log_dir=args.result_path + '/runs')
    losses = []

    if args.debug:
        np.random.seed(args.seed)
        torch.manual_seed(args.seed)
        if args.device == 'cuda':
            torch.cuda.manual_seed(args.seed)
        cudnn.benchmark = True
        cudnn.enabled=True
    param = args.param

    # build model and loss
    args.l1_criterion = nn.L1Loss().to(args.device)

    DOE_phase = Variable(param.DOE_phase_init.to(args.device), requires_grad=True)
    optics_optimizer = optim.Adam([DOE_phase], lr=args.optics_lr)

    total_step = 0
    train_loss = 0

    far_depth = [5,3,1]
    near_depth = [0.12,0.08,0.05]

    psf_far = []

    for depth in far_depth:
        psf_far.append(psf_thin_lens_far(args, depth))
    

    for epoch in trange(args.n_epochs, desc='Epoch'):
        step_loss = train_step(DOE_phase, optics_optimizer, total_step, psf_far, far_depth, near_depth, args)
        losses.append(step_loss.item())  # Collect loss for matplotlib
        writer.add_scalar('Loss/train', step_loss.item(), epoch)  # Log loss for TensorBoard
        
        total_step += 1
        train_loss += step_loss
        print('\n Epoch %d Loss: %f' % (epoch, step_loss))
        print('\n DOE phase shape: ', DOE_phase.shape)
        # save model
        if total_step % args.save_freq == 0:
            torch.save(DOE_phase, os.path.join(args.result_path,'DOE_phase_%03d.pt' % (total_step//args.save_freq)))
    
    writer.close()    

def main():
    parser = argparse.ArgumentParser(
        description='PSF based Obstruction-free DOE training',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    def none_or_str(value):
        if value == 'None':
            return None
        return value
    
    parser.add_argument('--debug', action="store_true", help='debug mode, train on validation data to speed up the process')
    parser.add_argument('--train_optics', action="store_true", help='optimize optical element design')
    parser.add_argument('--pretrained_DOE', default = None, type =none_or_str, help = 'use a pretrained DOE')
    parser.add_argument('--pretrained_G', default = None, type =none_or_str, help = 'use a pretrained G')
    parser.add_argument('--result_path', default = './ckpt/opt', type=str, help='dir to save models and checkpoints')
    parser.add_argument('--param_file', default= 'config/param_MV_1600.py', type=str, help='path to param file')

    parser.add_argument('--obstruction', default = 'dirt_raindrop', type = str, help = 'obsturction type')
    parser.add_argument('--sensor_noise', default = 0.008, type=float, help='sensor noise level')
    parser.add_argument('--n_epochs', default = 1000, type = int, help = 'max num of training epoch')
    parser.add_argument('--optics_lr', default=0.1, type=float, help='optical element learning rate')
    parser.add_argument('--G_lr', default=1e-4, type=float, help='network learning rate')

    parser.add_argument('--l1_loss_weight', default = 1, type = float, help = 'weight for L1 loss')
    parser.add_argument('--masked_loss_weight', default = 1, type = float, help = 'weight for masked loss (focus on obstructed scene)')
    parser.add_argument('--perceptual_loss_weight', default = 1, type = float, help = 'weight for perceptual loss')

    parser.add_argument('--log_freq', default=400, type=int, help = 'frequency (num_steps) of logging')
    parser.add_argument('--save_freq', default=50, type=int, help = 'frequency (num_steps) of saving checkpoint and visual performance')
    parser.add_argument('--seed', type=int, default=1234, help='random seed')
    parser.add_argument('--random_init', action="store_true", help='randomly initialize DOE phase')

    args = parser.parse_args()
    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'

    param = SourceFileLoader("param", args.param_file).load_module()
    param = convert_resolution(param,args)

    if args.pretrained_DOE is not None:
        if args.pretrained_DOE.endswith('.pt'):
            args.DOE_phase_init_ckpt = args.pretrained_DOE
        else:
            args.DOE_phase_init_ckpt = last_save(args.pretrained_DOE, 'DOE_phase_*')
        param.DOE_phase_init = torch.load(args.DOE_phase_init_ckpt, map_location='cpu').detach()

    if args.random_init is True:
        # zero initialization
        param.DOE_phase_init = torch.zeros(param.DOE_phase_init.shape, device=args.device)

        # param.DOE_phase_init = torch.rand(param.DOE_phase_init.shape, device=args.device) * 10
        print('ze initialized DOE phase')

    if args.pretrained_G is not None:
        args.G_init_ckpt = last_save(args.pretrained_G, 'G_*')
            
    save_settings(args, param)
    train(args)

if __name__ == '__main__':
    
    main()
